{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Rekognition Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the `DemoWebsite` URL which will be available in the Outputs section of the *Media Analysis Solution* CloudFormation stack. In the next cell replace the text `[DemoWebsite_URL]` with the URL that you copied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<h3>Media Analysis Solution</h3>\n",
    "<br>\n",
    "<object type=\"text/html\" data=\"[DemoWebsite_URL]\" width=\"1000\" height=\"600\"> <embed src=\"[DemoWebsite_URL]\"></embed></object>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Update the following values. \n",
    "* `region` - Make sure you select a region where all the AWS AI services are available.\n",
    "* `bucket_name` - Make sure you enter an existing bucket in the same region as above.\n",
    "* `bucket_prefix` - Enter a prefix if needed, else leave it blank. If you are entering prefix, end it with a slash(/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'eu-west-1' # Update it to your region of choice\n",
    "bucket_name = 'aws-mikasino-sagemaker' # Update it to the S3 bucket name\n",
    "bucket_prefix = '' # Make sure you include trailing slash (/) if you are adding a prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Here we are loading the needed libraries and uploading the video file to S3 for later use."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import boto3\n",
    "import IPython\n",
    "import time\n",
    "import json\n",
    "import urllib\n",
    "import urllib.request\n",
    "import random\n",
    "from datetime import datetime\n",
    "from prettytable import PrettyTable\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "polly = boto3.client('polly', region_name=region)\n",
    "s3 = boto3.client('s3', region_name=region)\n",
    "\n",
    "s3.upload_file('./jeff.mp4', bucket_name, bucket_prefix + 'jeff.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Amazon Polly Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are making an API call to convert text to speech. Text to be converted is in variable `Text` as SSML string. Using `VoiceId` as `Ruben` since it's a Dutch text. You shall update the text and select a differnt VoiceId based on the language of your preference. For the complete list of voice Ids check [the documentation](https://docs.aws.amazon.com/polly/latest/dg/voicelist.html). \n",
    "\n",
    "Response will be stored in a local file named *pollyresponse.mp3*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = polly.synthesize_speech(\n",
    "    Text=\"<speak> Wanneer komt er weer eens een Elfstedentocht?<amazon:breath duration='medium' volume='x-loud'/> \\\n",
    "    Helaas was de laaste elfstedentocht<emphasis level='reduced'> in 1997</emphasis>, \\\n",
    "   maar we hebben weer goede hoop voor dit jaar!</speak>\",\n",
    "    TextType=\"ssml\",\n",
    "    OutputFormat=\"mp3\",                                           \n",
    "    VoiceId=\"Ruben\")\n",
    "     \n",
    "outfile = \"pollyresponse.mp3\"\n",
    "data = response['AudioStream'].read()\n",
    "\n",
    "with open(outfile,'wb') as f:\n",
    "     f.write(data)\n",
    "\n",
    "# print (response)\n",
    "print('Converted text of %s characters to voice and stored it locally as file named %s' % (str(response['RequestCharacters']), outfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "You shall play the response by clicking the play button."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<audio width=\"360\" height=\"270\" controls src=\"pollyresponse.mp3\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Polly Custom Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon Polly supports custom lexicon which enables you to customize the pronunciation of words. For additional details, refer [the documenation](https://docs.aws.amazon.com/polly/latest/dg/managing-lexicons.html).\n",
    "\n",
    "Here we are creating a custom lexicon to properly covert internet slag to speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internet_slag_lexicon = '''<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<lexicon version=\"1.0\" \n",
    "      xmlns=\"http://www.w3.org/2005/01/pronunciation-lexicon\"\n",
    "      xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n",
    "      xsi:schemaLocation=\"http://www.w3.org/2005/01/pronunciation-lexicon \n",
    "        http://www.w3.org/TR/2007/CR-pronunciation-lexicon-20071212/pls.xsd\"\n",
    "      alphabet=\"ipa\" xml:lang=\"en-US\">\n",
    "  <lexeme>\n",
    "    <grapheme>La vita &#x00E8; bella</grapheme>\n",
    "    <phoneme>ˈlɑ ˈviːɾə ˈʔeɪ ˈbɛlə</phoneme>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>Roberto</grapheme>\n",
    "    <phoneme>ɹəˈbɛːɹɾoʊ</phoneme>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>Benigni</grapheme>\n",
    "    <phoneme>bɛˈniːnji</phoneme>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>IHAC</grapheme>\n",
    "    <alias>I have a customer</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>2day</grapheme>\n",
    "    <alias>Today</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>2moro</grapheme>\n",
    "    <alias>Tomorrow</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>2nite</grapheme>\n",
    "    <alias>Tonite</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>ASAP</grapheme>\n",
    "    <alias>As soon as possible</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>IIRC</grapheme>\n",
    "    <alias>If I remember correctly</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>POV</grapheme>\n",
    "    <alias>Point of View</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>TTYL</grapheme>\n",
    "    <alias>Talk to you later</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>THX</grapheme>\n",
    "    <alias>Thanks</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>YW</grapheme>\n",
    "    <alias>You are Welcome</alias>\n",
    "  </lexeme>\n",
    "</lexicon>'''\n",
    "\n",
    "lexicon = polly.put_lexicon(\n",
    "    Name='custom-lexicon-demo',\n",
    "    Content=internet_slag_lexicon\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Use Polly to synthesize speech without using custom lexicon and with custom lexicon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_convert='''IHAC looking for way to convert text based chat conversations to speech.\n",
    "IIRC that is possible through custom lexicon in polly. I want to know your POV on this.\n",
    "I have to respond back to the customer 2nite, hence can you pleaes let me know ASAP, THX.'''\n",
    "\n",
    "no_lex_res = polly.synthesize_speech(\n",
    "    Engine='neural',\n",
    "    Text='<speak>' + text_to_convert +'</speak>',\n",
    "    TextType=\"ssml\",\n",
    "    OutputFormat=\"mp3\",                                           \n",
    "    VoiceId=\"Joanna\")\n",
    "     \n",
    "of_nolex = \"neural_nolexicon.mp3\"\n",
    "data_nolex = no_lex_res['AudioStream'].read()\n",
    "\n",
    "with open(of_nolex,'wb') as f:\n",
    "     f.write(data_nolex)\n",
    "\n",
    "lex_res = polly.synthesize_speech(\n",
    "    Engine='neural',\n",
    "    Text='<speak>' + text_to_convert +'</speak>',\n",
    "    LexiconNames=['custom-lexicon-demo'],\n",
    "    TextType=\"ssml\",\n",
    "    OutputFormat=\"mp3\",                                           \n",
    "    VoiceId=\"Joanna\")\n",
    "     \n",
    "of_lex = \"neural_lexicon.mp3\"\n",
    "data_lex = lex_res['AudioStream'].read()\n",
    "\n",
    "with open(of_lex,'wb') as f:\n",
    "     f.write(data_lex)\n",
    "\n",
    "# print (response)\n",
    "print('Converted text of %s characters to voice and stored it locally as file named %s' % (str(lex_res['RequestCharacters']), of_lex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Listen to the synthesized speech without lexicon and with lexicon to hear the difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Lexicon\n",
    "\n",
    "<audio width=\"360\" height=\"270\" controls src=\"./neural_nolexicon.mp3\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Lexicon\n",
    "\n",
    "<audio width=\"360\" height=\"270\" controls src=\"./neural_lexicon.mp3\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Amazon Transcribe Demo\n",
    "\n",
    "Using Amazon Transcribe we are going to generate the text from the video file. Transcribe will provide a signed S3 URL which will contain the transcribed text in JSON forma. Output of the transcribe will contain the speaker identification labels, timestamp when a particular word was heard, etc.\n",
    "\n",
    "Click the below arrow to expand the video.\n",
    "\n",
    "*Before playing the video, start the transcribe job by executing the next cell since it will take few seconds to complete the transcribe job.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Video to be transcribed</summary>\n",
    "      <video width=\"640\" height=\"480\" controls src=\"./jeff.mp4\" />\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting mp4 to text\n",
    "transcribe = boto3.client('transcribe')\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d-%H%M%S')\n",
    "job_name = \"TranscribeDemo-\" + timestamp\n",
    "job_uri = 'https://s3-{}.amazonaws.com/{}/{}jeff.mp4'.format(region, bucket_name, bucket_prefix)\n",
    "transcribe.start_transcription_job(\n",
    "    TranscriptionJobName=job_name,\n",
    "    Media={'MediaFileUri': job_uri},\n",
    "    MediaFormat='mp4',\n",
    "    LanguageCode='en-US',\n",
    "    MediaSampleRateHertz=44100,\n",
    "    Settings={'MaxSpeakerLabels': 2,'ShowSpeakerLabels': True }    \n",
    ")\n",
    "print('Transcribing the video is in progress ', end='')\n",
    "while True:\n",
    "    status = transcribe.get_transcription_job(TranscriptionJobName=job_name)\n",
    "    if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "        print('')\n",
    "        print('Transcribing the video job completed with status %s\\n' % status['TranscriptionJob']['TranscriptionJobStatus'])\n",
    "        break\n",
    "    print('.', end='')\n",
    "    time.sleep(5)\n",
    "# pprint(status)\n",
    "url = status['TranscriptionJob']['Transcript']['TranscriptFileUri']\n",
    "print('Download the text output of transcribe job from the following URL:\\n%s ' % url)\n",
    "transcript='transcript_{}.json'.format(job_name)\n",
    "urllib.request.urlretrieve(url,transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Read the output of the transcribe job and print the text generated from the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = json.load(open(transcript))\n",
    "transcript_text = result['results']['transcripts'][0]['transcript']\n",
    "print(transcript_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now we are going to label the text based on the speaker labels to display the content specifically spoken by a speaker.\n",
    "\n",
    "We also use Amazon Comprehend to identify the sentiment of the text for both he speakers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# read the json output from disk (debugging)\n",
    "with open('asrOutput.json') as f:\n",
    "    data = json.load(f)\n",
    "'''\n",
    "\n",
    "data = json.load(open(transcript))\n",
    "\n",
    "# create a list to store start and stop times of the speaker in seconds\n",
    "spk_0 = []\n",
    "spk_1 = []\n",
    "\n",
    "# iterate over the speaker segments from the json\n",
    "for x in data['results']['speaker_labels']['segments']:\n",
    "        # check for which speaker a label was submitted\n",
    "        if x['speaker_label'] == 'spk_0':\n",
    "                # we need to convert float to int by multiplying *100, else we cannot use it later on to compare ranges\n",
    "                start         = int(float(x['start_time']) * 100)\n",
    "                end         = int(float(x['end_time']) * 100)\n",
    "\n",
    "                # append the start and stop times to a list\n",
    "                spk_0.append([start, end])\n",
    "\n",
    "        # check for which speaker a label was submitted\n",
    "        if x['speaker_label'] == 'spk_1':\n",
    "                # we need to convert float to int by multiplying *100, else we cannot use it later on to compare ranges\n",
    "                start         = int(float(x['start_time']) * 100)\n",
    "                end         = int(float(x['end_time']) * 100)\n",
    "\n",
    "                # append the start and stop times to a list\n",
    "                spk_1.append([start, end])\n",
    "\n",
    "res = []\n",
    "speaker0                 = []\n",
    "speaker1                 = []\n",
    "curr_speaker         = ''\n",
    "\n",
    "\n",
    "for x in data['results']['items']:\n",
    "        txt         = x['alternatives'][0]['content']\n",
    "        # check if the item has a start_time - if not, its probably punctuation which doesn't come with a timestamp. \n",
    "        if 'start_time' in x:\n",
    "                start         = int(float(x['start_time']) * 100)\n",
    "                end         = int(float(x['end_time']) * 100)\n",
    "                for y in spk_0:                        \n",
    "                        if start in range(y[0], y[1]) and end in range(y[0], y[1]):\n",
    "                                curr_speaker = 'spk_0'\n",
    "                for y in spk_1:                        \n",
    "                        if start in range(y[0], y[1]) and end in range(y[0], y[1]):\n",
    "                                curr_speaker = 'spk_1'\n",
    "        if curr_speaker == 'spk_0':\n",
    "                if x['type'] == 'punctuation' and txt != ',':\n",
    "                        speaker0.append(txt+'\\n')\n",
    "                elif txt == ',' or txt[0].isupper():\n",
    "                        speaker0.append(txt)\n",
    "                else:\n",
    "                        speaker0.append(' '+txt)\n",
    "        if curr_speaker == 'spk_1':\n",
    "                if x['type'] == 'punctuation' and txt != ',':\n",
    "                        speaker1.append(txt+'\\n')\n",
    "                elif txt == ',' or txt[0].isupper():\n",
    "                        speaker1.append(txt)\n",
    "                else:\n",
    "                        speaker1.append(' '+txt)\n",
    "\n",
    "# check sentiment of both speakers\n",
    "def check_sentiment(x, y):\n",
    "        c = boto3.client(service_name='comprehend', region_name='eu-west-1')\n",
    "        s = y+','\n",
    "        x = c.detect_sentiment(Text=x, LanguageCode='en')\n",
    "        y =  ' Mixed : '+str(x['SentimentScore']['Mixed'])\n",
    "        y += '\\t Positive :'+str(x['SentimentScore']['Positive'])\n",
    "        y += '\\t Negative : '+str(x['SentimentScore']['Negative'])\n",
    "        y += '\\t Neutral : '+str(x['SentimentScore']['Neutral'])\n",
    "        y += '\\t Sentiment : '+str(x['Sentiment'])\n",
    "        return y\n",
    "\n",
    "\n",
    "# print full text for both speakers\n",
    "print('Speaker1:')\n",
    "print(''.join(speaker1))\n",
    "print('Sentiment of speaker 1 : '+check_sentiment(''.join(speaker1), 'speaker 1 '))\n",
    "print('\\n')\n",
    "print('Speaker2:')\n",
    "print(''.join(speaker0))\n",
    "print('\\n')\n",
    "print('Sentiment of speaker 2 : '+check_sentiment(''.join(speaker0), 'speaker 0 '))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Amazon Translate Demo\n",
    "\n",
    "Convert the transribed text to German language using Amazon Translate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "translate = boto3.client('translate', region_name=region)\n",
    "\n",
    "message = transcript_text\n",
    "\n",
    "result=translate.translate_text(\n",
    "    Text=message,\n",
    "    SourceLanguageCode='en',\n",
    "    TargetLanguageCode='de'\n",
    ")\n",
    "\n",
    "# print(json.dumps(result, sort_keys=True, indent=4, default=str))\n",
    "print(result['TranslatedText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Amazon Comprehend Demo\n",
    "\n",
    "Now using Amazon Comprehend detect the language from the above text. By providing the detected language as input detect the sentiment, entities and key phrases in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehend = boto3.client('comprehend')\n",
    "\n",
    "text = result['TranslatedText']\n",
    "\n",
    "language_detected = comprehend.detect_dominant_language(Text=text)['Languages'][0]['LanguageCode']\n",
    "\n",
    "entity_res = comprehend.detect_entities(Text=text, LanguageCode=language_detected)\n",
    "senti_res = comprehend.detect_sentiment(Text=text, LanguageCode=language_detected)\n",
    "key_res = comprehend.detect_key_phrases(Text=text, LanguageCode=language_detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Language detected is %s \\n' % language_detected)\n",
    "\n",
    "print('Sentiment of the text has been identified as %s with the score of %s \\n' % (senti_res['Sentiment'], senti_res['SentimentScore'][senti_res['Sentiment'].title()]))\n",
    "\n",
    "keyphrases = [[], [], []]\n",
    "for k in key_res['KeyPhrases']:\n",
    "    if k['Score'] > .99:\n",
    "        keyphrases[0].append(k['Text'] + '\\n')\n",
    "    elif k['Score'] > .98:\n",
    "        keyphrases[1].append(k['Text'] + '\\n')\n",
    "    elif k['Score'] > .97:\n",
    "        keyphrases[2].append(k['Text'] + '\\n')\n",
    "           \n",
    "print('Key Phrases identified from the text:')\n",
    "\n",
    "keytable = PrettyTable(['Score', 'Key Phrases'])\n",
    "if keyphrases[0]:\n",
    "    keytable.add_row(['.99', ''.join(keyphrases[0])])\n",
    "    keytable.add_row(['--', '--------------------'])\n",
    "if keyphrases[1]:\n",
    "    keytable.add_row(['.98', ''.join(keyphrases[1])])\n",
    "    keytable.add_row(['--', '--------------------'])\n",
    "if keyphrases[2]:\n",
    "    keytable.add_row(['.97', ''.join(keyphrases[2])])\n",
    "print(keytable)\n",
    "print('\\n')\n",
    "\n",
    "entity_thershold = 0.80\n",
    "\n",
    "topentity = {}\n",
    "for e in entity_res['Entities']:\n",
    "    if e['Score'] > entity_thershold:\n",
    "        topentity[e['Score']] = {e['Text']: e['Type']}\n",
    "        \n",
    "top10 = sorted(topentity, reverse=True)[:10]\n",
    "\n",
    "table = PrettyTable(['Text', 'Type','Score'])\n",
    "for t in top10:\n",
    "    table.add_row([list(topentity[t].keys())[0], list(topentity[t].values())[0], t])\n",
    "    \n",
    "print('Top 10 entities identified:')    \n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Real-time Audio Transcription using Amazon Transcribe Websockets\n",
    "\n",
    "Earlier we have seen how to transcribe an existing video file stored in S3. Now let's look at an example how we can to real-time audio transcripton using the Amazon Traanscribe Websockets API.\n",
    "\n",
    "*You have to update the text `[AMPLIFY_URL]` with the actual Amplify Console URL created as part of the prerequisites. You also need to key in the access key and secret key of the user that you created as part of the prerequisites.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<h3>Real-time Audio Transcription</h3>\n",
    "<br>\n",
    "<object type=\"text/html\" data=[AMPLIFY_URL] width=\"1000\" height=\"600\"> <embed src=\"[AMPLIFY_URL]\"></embed></object>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
