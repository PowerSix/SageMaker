{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Notebook setup\n",
    "\n",
    "Update the following values:\n",
    "* `region` - Make sure you select a region where all the AWS AI services are available.\n",
    "* `bucket_name` - Make sure you enter an existing bucket in the same region as above.\n",
    "* `bucket_prefix` - Enter a prefix if needed, else leave it blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'eu-west-1' # Update it to your region of choice\n",
    "bucket_name = 'aws-mikasino-sagemaker' # Update it to the S3 bucket name\n",
    "bucket_prefix = '' # Make sure you include trailing slash (/) if you are adding a prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the necessary libraries and upload the video file to S3 for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import IPython\n",
    "import time\n",
    "import json\n",
    "import urllib\n",
    "import urllib.request\n",
    "import random\n",
    "from datetime import datetime\n",
    "#from prettytable import PrettyTable\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "polly = boto3.client('polly', region_name=region)\n",
    "s3 = boto3.client('s3', region_name=region)\n",
    "\n",
    "s3.upload_file('./jeff.mp4', bucket_name, bucket_prefix + 'jeff.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Demo #1: Amazon Polly\n",
    "\n",
    "We're making an API call to Amazon Polly service here to convert the text to speech. Text to be converted is in variable `Text` as an SSML string. It will be converted to `mp3` format and stored in a local file.  \n",
    "The voice is controlled by setting the `VoiceId` to `Salli`.\n",
    "\n",
    "For the full list of voices to be used with Polly check [the documentation page](https://docs.aws.amazon.com/en_pv/polly/latest/dg/voicelist.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted text to voice and stored it locally as polly-salli-intro.mp3\n"
     ]
    }
   ],
   "source": [
    "response = polly.synthesize_speech(\n",
    "  Text=\"<speak><amazon:auto-breaths frequency='low' volume='soft' duration='x-short'>Amazon Polly is a Text-to-Speech service, \\\n",
    "  that uses advanced deep learning technologies to synthesize speech that sounds like a human. With dozens of lifelike voices, variety of languages, \\\n",
    "  you can select the ideal voice and build speech-enabled applications that work in many different countries.</amazon:auto-breaths></speak>\",\n",
    "  TextType=\"ssml\",\n",
    "  OutputFormat=\"mp3\",                                           \n",
    "  VoiceId=\"Salli\")\n",
    "    \n",
    "outfile = \"polly-salli-intro.mp3\"\n",
    "data = response['AudioStream'].read()\n",
    "\n",
    "with open(outfile,'wb') as f:\n",
    "  f.write(data)\n",
    "\n",
    "print('Converted text to voice and stored it locally as %s' % (outfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<audio width=\"360\" height=\"270\" controls src=\"polly-salli-intro.mp3\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon Polly supports standard SSML tags such as prosody, which enables you to control the volume, rate, and pitch of the speech out.  \n",
    "In the following example, we demonstrate how you can use manual `<amazon:breath>` and `<prosody>` tags together to convey emotional or dramatic tone in speech.  \n",
    "Let's try with a scared voice of Matthew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted text to voice and stored it locally as polly-matthew-scared.mp3\n"
     ]
    }
   ],
   "source": [
    "response = polly.synthesize_speech(\n",
    "  Text=\"<speak><amazon:breath duration='medium' volume='x-loud'/><prosody rate='115%'> <prosody volume='x-loud'> Salli? <break time='300ms'/> \\\n",
    "  </prosody> Is that you?</prosody></speak>\",\n",
    "  TextType=\"ssml\",\n",
    "  OutputFormat=\"mp3\",                                           \n",
    "  VoiceId=\"Matthew\")\n",
    "    \n",
    "outfile = \"polly-matthew-scared.mp3\"\n",
    "data = response['AudioStream'].read()\n",
    "\n",
    "with open(outfile,'wb') as f:\n",
    "  f.write(data)\n",
    "\n",
    "print('Converted text to voice and stored it locally as %s' % (outfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<audio width=\"360\" height=\"270\" controls src=\"polly-matthew-scared.mp3\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example uses an uncertain voice of Matthew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted text to voice and stored it locally as polly-matthew-uncertain.mp3\n"
     ]
    }
   ],
   "source": [
    "response = polly.synthesize_speech(\n",
    "  Text=\"<speak> <prosody rate='60%'> I am not sure <amazon:breath duration='x-long' volume='soft'/> <break time='150ms'/> </prosody> <prosody rate='90%'>I think I need to think about it. </prosody> </speak>\",\n",
    "  TextType=\"ssml\",\n",
    "  OutputFormat=\"mp3\",                                           \n",
    "  VoiceId=\"Matthew\")\n",
    "    \n",
    "outfile = \"polly-matthew-uncertain.mp3\"\n",
    "data = response['AudioStream'].read()\n",
    "\n",
    "with open(outfile,'wb') as f:\n",
    "  f.write(data)\n",
    "\n",
    "print('Converted text to voice and stored it locally as %s' % (outfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<audio width=\"360\" height=\"270\" controls src=\"polly-matthew-uncertain.mp3\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last example is a breathless voice of Salli.  \n",
    "By incorporating breath sounds into speech output from text, Polly is able to provide more naturally sounding speech, particularly for long-form text narration.  \n",
    "Visit the [Amazon Polly documentation](http://docs.aws.amazon.com/polly/latest/dg/supported-ssml.html) for more information on SSML tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted text to voice and stored it locally as polly-salli-breathless.mp3\n"
     ]
    }
   ],
   "source": [
    "response = polly.synthesize_speech(\n",
    "  Text=\"<speak> <amazon:breath duration='long' volume='x-loud'/><prosody rate='120%'> <prosody volume='loud'> Wow! <amazon:breath duration='long' volume='loud'/> \\\n",
    "  </prosody> That was quite fast <amazon:breath duration='medium' volume='x-loud'/> I almost beat my personal best time on this track. </prosody> </speak>\",\n",
    "  TextType=\"ssml\",\n",
    "  OutputFormat=\"mp3\",                                           \n",
    "  VoiceId=\"Salli\")\n",
    "    \n",
    "outfile = \"polly-salli-breathless.mp3\"\n",
    "data = response['AudioStream'].read()\n",
    "\n",
    "with open(outfile,'wb') as f:\n",
    "  f.write(data)\n",
    "\n",
    "print('Converted text to voice and stored it locally as %s' % (outfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<audio width=\"360\" height=\"270\" controls src=\"polly-salli-breathless.mp3\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Custom Lexicon for Polly\n",
    "\n",
    "Pronunciation lexicons enable you to customize the pronunciation of words. They give you additional control over how Polly pronounces words uncommon to the selected language.  \n",
    "\n",
    "Examples of lexicon usage can be:\n",
    "* If your text includes an acronym, such as W3C. Use a lexicon to define an alias for this so that it is read in the full, expanded form - World Wide Web Consortium.\n",
    "* Common words are sometimes stylized with numbers taking the place of letters, as with \"g3t sm4rt\" (get smart). Humans can read these words correctly. However, a Text-to-Speech (TTS) engine reads the text literally, pronouncing the name exactly as it is spelled. Use a lexicon to customize the synthesized speech for proper pronunciation - get smart.\n",
    "\n",
    "For additional details about Polly Lexicons, refer to the [Managing Lexicons page](https://docs.aws.amazon.com/polly/latest/dg/managing-lexicons.html).\n",
    "\n",
    "Let's use a custom lexicon here to properly convert internet slangs to speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlex = '''<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<lexicon version=\"1.0\" \n",
    "      xmlns=\"http://www.w3.org/2005/01/pronunciation-lexicon\"\n",
    "      xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n",
    "      xsi:schemaLocation=\"http://www.w3.org/2005/01/pronunciation-lexicon \n",
    "        http://www.w3.org/TR/2007/CR-pronunciation-lexicon-20071212/pls.xsd\"\n",
    "      alphabet=\"ipa\" \n",
    "      xml:lang=\"en-US\">\n",
    "  <lexeme>\n",
    "    <grapheme>W3C</grapheme>\n",
    "    <alias>World Wide Web Consortium</alias>\n",
    "  </lexeme>\n",
    "</lexicon>'''\n",
    "\n",
    "internetslanglexicon = '''<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<lexicon version=\"1.0\" \n",
    "      xmlns=\"http://www.w3.org/2005/01/pronunciation-lexicon\"\n",
    "      xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n",
    "      xsi:schemaLocation=\"http://www.w3.org/2005/01/pronunciation-lexicon \n",
    "        http://www.w3.org/TR/2007/CR-pronunciation-lexicon-20071212/pls.xsd\"\n",
    "      alphabet=\"ipa\" xml:lang=\"en-US\">\n",
    "  <lexeme>\n",
    "    <grapheme>La vita &#x00E8; bella</grapheme>\n",
    "    <phoneme>ˈlɑ ˈviːɾə ˈʔeɪ ˈbɛlə</phoneme>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>Roberto</grapheme>\n",
    "    <phoneme>ɹəˈbɛːɹɾoʊ</phoneme>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>Benigni</grapheme>\n",
    "    <phoneme>bɛˈniːnji</phoneme>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>IHAC</grapheme>\n",
    "    <alias>I have a customer</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>2day</grapheme>\n",
    "    <alias>Today</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>2moro</grapheme>\n",
    "    <alias>Tomorrow</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>2nite</grapheme>\n",
    "    <alias>Tonite</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>ASAP</grapheme>\n",
    "    <alias>As soon as possible</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>IIRC</grapheme>\n",
    "    <alias>If I remember correctly</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>POV</grapheme>\n",
    "    <alias>Point of View</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>TTYL</grapheme>\n",
    "    <alias>Talk to you later</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>THX</grapheme>\n",
    "    <alias>Thanks</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>YW</grapheme>\n",
    "    <alias>You are Welcome</alias>\n",
    "  </lexeme>\n",
    "</lexicon>'''\n",
    "# lexicon_data = lexicon_file.read()\n",
    "# response = polly.put_lexicon(Name=arguments.name, Content=lexicon_data)\n",
    "        \n",
    "lexicon = polly.put_lexicon(\n",
    "    Name = 'customlexicon',\n",
    "    Content = internetslanglexicon\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Use Polly to synthesize speech without using custom lexicon and with custom lexicon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted text to voice and stored it locally as polly-joanna-neural_nolexicon.mp3\n",
      "Converted text to voice and stored it locally as polly-joanna-neural_lexicon.mp3\n"
     ]
    }
   ],
   "source": [
    "text_to_convert='''IHAC looking for way to convert text based chat conversations to speech.\n",
    "IIRC, that is possible through custom lexicon in Polly. I want to know your POV on this.\n",
    "I have to respond back to the customer 2nite, hence can you please let me know ASAP, THX.'''\n",
    "\n",
    "no_lex_res = polly.synthesize_speech(\n",
    "  Engine='neural',\n",
    "  Text='<speak>' + text_to_convert +'</speak>',\n",
    "  TextType=\"ssml\",\n",
    "  OutputFormat=\"mp3\",                                           \n",
    "  VoiceId=\"Joanna\")\n",
    "     \n",
    "outfile_nolex = \"polly-joanna-neural_nolexicon.mp3\"\n",
    "data_nolex = no_lex_res['AudioStream'].read()\n",
    "\n",
    "with open(outfile_nolex,'wb') as f:\n",
    "  f.write(data_nolex)\n",
    "\n",
    "print('Converted text to voice and stored it locally as %s' % (outfile_nolex))\n",
    "\n",
    "lex_res = polly.synthesize_speech(\n",
    "  Engine='neural',\n",
    "  Text='<speak>' + text_to_convert +'</speak>',\n",
    "  LexiconNames=['customlexicon'],\n",
    "  TextType=\"ssml\",\n",
    "  OutputFormat=\"mp3\",                                           \n",
    "  VoiceId=\"Joanna\")\n",
    "     \n",
    "outfile_lex = \"polly-joanna-neural_lexicon.mp3\"\n",
    "data_lex = lex_res['AudioStream'].read()\n",
    "\n",
    "with open(outfile_lex,'wb') as f:\n",
    "  f.write(data_lex)\n",
    "\n",
    "print('Converted text to voice and stored it locally as %s' % (outfile_lex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Listen to the synthesized speech without lexicon and with lexicon to hear the difference.\n",
    "\n",
    "Text:  \n",
    "IHAC looking for way to convert text based chat conversations to speech.  \n",
    "IIRC, that is possible through custom lexicon in Polly. I want to know your POV on this.  \n",
    "I have to respond back to the customer 2nite, hence can you please let me know ASAP, THX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Lexicon\n",
    "\n",
    "<audio width=\"360\" height=\"270\" controls src=\"polly-joanna-neural_nolexicon.mp3\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Lexicon\n",
    "\n",
    "<audio width=\"360\" height=\"270\" controls src=\"polly-joanna-neural_lexicon.mp3\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Demo #1: Amazon Transcribe\n",
    "\n",
    "Using Amazon Transcribe we are going to generate the text from the video file. Transcribe will provide a signed S3 URL which will contain the transcribed text in JSON forma. Output of the transcribe will contain the speaker identification labels, timestamp when a particular word was heard, etc.\n",
    "\n",
    "Click the below arrow to expand the video.\n",
    "\n",
    "*Before playing the video, start the transcribe job by executing the next cell since it will take few seconds to complete the transcribe job.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Video to be transcribed</summary>\n",
    "  <video width=\"640\" height=\"480\" controls src=\"./jeff.mp4\" />\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing the video is in progress .................\n",
      "Transcribing the video job completed with status COMPLETED\n",
      "\n",
      "Download the text output of transcribe job from the following URL:\n",
      "https://s3.eu-west-1.amazonaws.com/aws-transcribe-eu-west-1-prod/892616959688/TranscribeDemo-2019-10-30-232724/0471a2ba-b888-447f-b4d5-339242572f39/asrOutput.json?X-Amz-Security-Token=AgoJb3JpZ2luX2VjEL%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCWV1LXdlc3QtMSJHMEUCIQDK3uvTQ2i9DKFZ1Ru%2FVt%2FvxlNX10Ql11sMLwDv4id9%2FQIgUm8TPWYh4BvIytu5mxqmgEOpaPpJqmMIRNRmMMKMm%2BoqhQQIyP%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FARABGgw1ODcwMTc2NjM0MTciDBqLLaSH2skyJ%2BsrEyrZA5hkBOY%2Bho8GWhqj9%2Fcm0vGTTD7hXkUD8pIxPK9VPvOMgwC9mV7cny8dIL8LkIfRJjyFtyqHhl1rbSLXOuYCNXa1i58LKp7UwnfBxMPvT8vMt%2FA64xKRnYCW6S7LtOOAHAwyKlrb4J4Ciy%2FHF%2Bkd3Ob6Qp1ltTfMaLdRAHQxFBLvyqG74BYsPLzpiwZrA177hbi1UpY23SvmWm6gJvCY66QzBtbGXIxiU%2F4yOcNXFyCZ2gbtL4NuIcHkKRN79whtGmuad2JW%2BzngblzZEDbFI%2FXnZS%2FvIq0b13o13d3aIz35FKL3dQY1TbCUpodCWbXiRZFlN1qe8zyQgSbN24kLHDaMzXDCvrsNUf1iRjhBwNTe6XGes0um7vcdKELWxTwsGDLjsCYcRHTzA5VeduTxfed%2Btw%2Bx3kX80VKNVqhgdEja98U7jeFN%2BC3T%2BTOrOhE0TMYFXUg9NyzBvwHQk%2Bz4awlHUvD3iHR2gV7mNXJPlKvKHnwFwd6Q4cj4HyU2TKV238Ttk%2F0oQ4dZA%2Foh1y4GEyWwQJxYPz24xd8eEKY9nfVZz4lpuhn7uD8VS6qZ9vhYFhAamTIhJx3P01p0AQBFR0IJb4Q9YSlwfTGjynXl%2FlS5V95S%2F33mXPSkMKmt6O0FOrQB%2FSXfpWCp6xrtTLi4B89zJ5pcdA2CQiGhg5GaegMi9kkTVyfkTW63eZUm6NIB3Z4MtWd5oNepfyvl67mhRN1X98hLYRVwCcTWmAfBoL3htMYvi5v3%2BlZ1B2YgZlFXiCnZUIdrRCFTBNXCUnuECPMTY%2FjIHeAapWsYMDgSZyDejVHHQ0FQHES0HE%2Bz0sWulI2GtIlMpialEwwAfTvKWCpEDxx4GyGzxiEObkuvYToLs3uwFTHX&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20191030T232850Z&X-Amz-SignedHeaders=host&X-Amz-Expires=899&X-Amz-Credential=ASIAYRLH2WO44QR7Z4LU%2F20191030%2Feu-west-1%2Fs3%2Faws4_request&X-Amz-Signature=b190705697aec3f9ca83e85bb6c11201d378ebcbb157c2cf8260d67915126248 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('transcript_TranscribeDemo-2019-10-30-232724.json',\n",
       " <http.client.HTTPMessage at 0x7f5bdc11f518>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting mp4 to text\n",
    "transcribe = boto3.client('transcribe')\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d-%H%M%S')\n",
    "job_name = \"TranscribeDemo-\" + timestamp\n",
    "job_uri = 'https://s3-{}.amazonaws.com/{}/{}jeff.mp4'.format(region, bucket_name, bucket_prefix)\n",
    "transcribe.start_transcription_job(\n",
    "    TranscriptionJobName=job_name,\n",
    "    Media={'MediaFileUri': job_uri},\n",
    "    MediaFormat='mp4',\n",
    "    LanguageCode='en-US',\n",
    "    MediaSampleRateHertz=44100,\n",
    "    Settings={'MaxSpeakerLabels': 2,'ShowSpeakerLabels': True }    \n",
    ")\n",
    "print('Transcribing the video is in progress ', end='')\n",
    "while True:\n",
    "    status = transcribe.get_transcription_job(TranscriptionJobName=job_name)\n",
    "    if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "        print('')\n",
    "        print('Transcribing the video job completed with status %s\\n' % status['TranscriptionJob']['TranscriptionJobStatus'])\n",
    "        break\n",
    "    print('.', end='')\n",
    "    time.sleep(5)\n",
    "# pprint(status)\n",
    "url = status['TranscriptionJob']['Transcript']['TranscriptFileUri']\n",
    "print('Download the text output of transcribe job from the following URL:\\n%s ' % url)\n",
    "transcript='transcript_{}.json'.format(job_name)\n",
    "urllib.request.urlretrieve(url,transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Read the output of the transcribe job and print the text generated from the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I guess my first question is, Is this Is this the underpinnings of tech over the next 10 years as we seem to be emerging from the period of frantic growth and development in smartphones? Well, I think it's I think it's gigantic. Um, I do, I think, natural language understanding, I think machine learning in general, Artificial intelligence. Uh, this. It's hard to overstate how big of an impact it's gonna have on society over the next 20 years, so\n"
     ]
    }
   ],
   "source": [
    "result = json.load(open(transcript))\n",
    "transcript_text = result['results']['transcripts'][0]['transcript']\n",
    "print(transcript_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now we are going to label the text based on the speaker labels to display the content specifically spoken by a speaker.\n",
    "\n",
    "We also use Amazon Comprehend to identify the sentiment of the text for both he speakers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker1:\n",
      "I guess my first question is,Is thisIs this the underpinnings of tech over the next 10 years as we seem to be emerging from the period of frantic growth and development in smartphones?\n",
      "Well,I think it's\n",
      "Sentiment of speaker 1 :  Mixed : 2.5586166884750128e-05\t Positive :0.021759752184152603\t Negative : 0.13760659098625183\t Neutral : 0.8406080603599548\t Sentiment : NEUTRAL\n",
      "\n",
      "\n",
      "Speaker2:\n",
      "I think it's gigantic.\n",
      "Um,I do,I think, natural language understanding,I think machine learning in general,Artificial intelligence.\n",
      "Uh, this.\n",
      "It's hard to overstate how big of an impact it's gonna have on society over the next 20 years, so\n",
      "\n",
      "\n",
      "Sentiment of speaker 2 :  Mixed : 1.1363149496901315e-05\t Positive :0.4650130271911621\t Negative : 0.0057877665385603905\t Neutral : 0.529187798500061\t Sentiment : NEUTRAL\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# read the json output from disk (debugging)\n",
    "with open('asrOutput.json') as f:\n",
    "    data = json.load(f)\n",
    "'''\n",
    "\n",
    "data = json.load(open(transcript))\n",
    "\n",
    "# create a list to store start and stop times of the speaker in seconds\n",
    "spk_0 = []\n",
    "spk_1 = []\n",
    "\n",
    "# iterate over the speaker segments from the json\n",
    "for x in data['results']['speaker_labels']['segments']:\n",
    "        # check for which speaker a label was submitted\n",
    "        if x['speaker_label'] == 'spk_0':\n",
    "                # we need to convert float to int by multiplying *100, else we cannot use it later on to compare ranges\n",
    "                start         = int(float(x['start_time']) * 100)\n",
    "                end         = int(float(x['end_time']) * 100)\n",
    "\n",
    "                # append the start and stop times to a list\n",
    "                spk_0.append([start, end])\n",
    "\n",
    "        # check for which speaker a label was submitted\n",
    "        if x['speaker_label'] == 'spk_1':\n",
    "                # we need to convert float to int by multiplying *100, else we cannot use it later on to compare ranges\n",
    "                start         = int(float(x['start_time']) * 100)\n",
    "                end         = int(float(x['end_time']) * 100)\n",
    "\n",
    "                # append the start and stop times to a list\n",
    "                spk_1.append([start, end])\n",
    "\n",
    "res = []\n",
    "speaker0                 = []\n",
    "speaker1                 = []\n",
    "curr_speaker         = ''\n",
    "\n",
    "\n",
    "for x in data['results']['items']:\n",
    "        txt         = x['alternatives'][0]['content']\n",
    "        # check if the item has a start_time - if not, its probably punctuation which doesn't come with a timestamp. \n",
    "        if 'start_time' in x:\n",
    "                start         = int(float(x['start_time']) * 100)\n",
    "                end         = int(float(x['end_time']) * 100)\n",
    "                for y in spk_0:                        \n",
    "                        if start in range(y[0], y[1]) and end in range(y[0], y[1]):\n",
    "                                curr_speaker = 'spk_0'\n",
    "                for y in spk_1:                        \n",
    "                        if start in range(y[0], y[1]) and end in range(y[0], y[1]):\n",
    "                                curr_speaker = 'spk_1'\n",
    "        if curr_speaker == 'spk_0':\n",
    "                if x['type'] == 'punctuation' and txt != ',':\n",
    "                        speaker0.append(txt+'\\n')\n",
    "                elif txt == ',' or txt[0].isupper():\n",
    "                        speaker0.append(txt)\n",
    "                else:\n",
    "                        speaker0.append(' '+txt)\n",
    "        if curr_speaker == 'spk_1':\n",
    "                if x['type'] == 'punctuation' and txt != ',':\n",
    "                        speaker1.append(txt+'\\n')\n",
    "                elif txt == ',' or txt[0].isupper():\n",
    "                        speaker1.append(txt)\n",
    "                else:\n",
    "                        speaker1.append(' '+txt)\n",
    "\n",
    "# check sentiment of both speakers\n",
    "def check_sentiment(x, y):\n",
    "        c = boto3.client(service_name='comprehend', region_name='eu-west-1')\n",
    "        s = y+','\n",
    "        x = c.detect_sentiment(Text=x, LanguageCode='en')\n",
    "        y =  ' Mixed : '+str(x['SentimentScore']['Mixed'])\n",
    "        y += '\\t Positive :'+str(x['SentimentScore']['Positive'])\n",
    "        y += '\\t Negative : '+str(x['SentimentScore']['Negative'])\n",
    "        y += '\\t Neutral : '+str(x['SentimentScore']['Neutral'])\n",
    "        y += '\\t Sentiment : '+str(x['Sentiment'])\n",
    "        return y\n",
    "\n",
    "\n",
    "# print full text for both speakers\n",
    "print('Speaker1:')\n",
    "print(''.join(speaker1))\n",
    "print('Sentiment of speaker 1 : '+check_sentiment(''.join(speaker1), 'speaker 1 '))\n",
    "print('\\n')\n",
    "print('Speaker2:')\n",
    "print(''.join(speaker0))\n",
    "print('\\n')\n",
    "print('Sentiment of speaker 2 : '+check_sentiment(''.join(speaker0), 'speaker 0 '))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Amazon Translate Demo\n",
    "\n",
    "Convert the transribed text to German language using Amazon Translate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ich denke, meine erste Frage ist, ist das die Grundlagen der Technologie in den nächsten 10 Jahren, da wir aus der Zeit des hektischen Wachstums und der Entwicklung in Smartphones entstehen scheinen? Nun, ich glaube, ich denke, es ist gigantisch. Ähm, ich denke, natürliches Sprachverständnis, ich denke, maschinelles Lernen im Allgemeinen, künstliche Intelligenz. Äh, das hier. Es ist schwer zu übertreiben, wie groß es für die Gesellschaft in den nächsten 20 Jahren sein wird, also\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "translate = boto3.client('translate', region_name=region)\n",
    "\n",
    "message = transcript_text\n",
    "\n",
    "result=translate.translate_text(\n",
    "    Text=message,\n",
    "    SourceLanguageCode='en',\n",
    "    TargetLanguageCode='de'\n",
    ")\n",
    "\n",
    "# print(json.dumps(result, sort_keys=True, indent=4, default=str))\n",
    "print(result['TranslatedText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Amazon Comprehend Demo\n",
    "\n",
    "Now using Amazon Comprehend detect the language from the above text. By providing the detected language as input detect the sentiment, entities and key phrases in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehend = boto3.client('comprehend')\n",
    "\n",
    "text = result['TranslatedText']\n",
    "\n",
    "language_detected = comprehend.detect_dominant_language(Text=text)['Languages'][0]['LanguageCode']\n",
    "\n",
    "entity_res = comprehend.detect_entities(Text=text, LanguageCode=language_detected)\n",
    "senti_res = comprehend.detect_sentiment(Text=text, LanguageCode=language_detected)\n",
    "key_res = comprehend.detect_key_phrases(Text=text, LanguageCode=language_detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language detected is de \n",
      "\n",
      "Sentiment of the text has been identified as NEUTRAL with the score of 0.9595580697059631 \n",
      "\n",
      "Key Phrases identified from the text:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'PrettyTable' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-538bac76e494>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Key Phrases identified from the text:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mkeytable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPrettyTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Key Phrases'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeyphrases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mkeytable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'.99'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyphrases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PrettyTable' is not defined"
     ]
    }
   ],
   "source": [
    "print('Language detected is %s \\n' % language_detected)\n",
    "\n",
    "print('Sentiment of the text has been identified as %s with the score of %s \\n' % (senti_res['Sentiment'], senti_res['SentimentScore'][senti_res['Sentiment'].title()]))\n",
    "\n",
    "keyphrases = [[], [], []]\n",
    "for k in key_res['KeyPhrases']:\n",
    "    if k['Score'] > .99:\n",
    "        keyphrases[0].append(k['Text'] + '\\n')\n",
    "    elif k['Score'] > .98:\n",
    "        keyphrases[1].append(k['Text'] + '\\n')\n",
    "    elif k['Score'] > .97:\n",
    "        keyphrases[2].append(k['Text'] + '\\n')\n",
    "           \n",
    "print('Key Phrases identified from the text:')\n",
    "\n",
    "keytable = PrettyTable(['Score', 'Key Phrases'])\n",
    "if keyphrases[0]:\n",
    "    keytable.add_row(['.99', ''.join(keyphrases[0])])\n",
    "    keytable.add_row(['--', '--------------------'])\n",
    "if keyphrases[1]:\n",
    "    keytable.add_row(['.98', ''.join(keyphrases[1])])\n",
    "    keytable.add_row(['--', '--------------------'])\n",
    "if keyphrases[2]:\n",
    "    keytable.add_row(['.97', ''.join(keyphrases[2])])\n",
    "print(keytable)\n",
    "print('\\n')\n",
    "\n",
    "entity_thershold = 0.80\n",
    "\n",
    "topentity = {}\n",
    "for e in entity_res['Entities']:\n",
    "    if e['Score'] > entity_thershold:\n",
    "        topentity[e['Score']] = {e['Text']: e['Type']}\n",
    "        \n",
    "top10 = sorted(topentity, reverse=True)[:10]\n",
    "\n",
    "table = PrettyTable(['Text', 'Type','Score'])\n",
    "for t in top10:\n",
    "    table.add_row([list(topentity[t].keys())[0], list(topentity[t].values())[0], t])\n",
    "    \n",
    "print('Top 10 entities identified:')    \n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Real-time Audio Transcription using Amazon Transcribe Websockets\n",
    "\n",
    "Earlier we have seen how to transcribe an existing video file stored in S3. Now let's look at an example how we can to real-time audio transcripton using the Amazon Traanscribe Websockets API.\n",
    "\n",
    "*You have to update the text `[AMPLIFY_URL]` with the actual Amplify Console URL created as part of the prerequisites. You also need to key in the access key and secret key of the user that you created as part of the prerequisites.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Amazon Rekognition\n",
    "\n",
    "Get the DemoWebsite URL which will be available in the Outputs section of the Media Analysis Solution CloudFormation stack. In the next cell replace the text [DemoWebsite_URL] with the URL that you copied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Real-time Audio Transcription</h3>\n",
       "<br>\n",
       "<object type=\"text/html\" data=[AMPLIFY_URL] width=\"1000\" height=\"600\"> <embed src=\"[AMPLIFY_URL]\"></embed></object>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<h3>Real-time Audio Transcription</h3>\n",
    "<br>\n",
    "<object type=\"text/html\" data=[AMPLIFY_URL] width=\"1000\" height=\"600\"> <embed src=\"[AMPLIFY_URL]\"></embed></object>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
