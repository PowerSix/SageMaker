{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS AI Services Demo\n",
    "\n",
    "1. Prerequisites\n",
    "1. Notebook setup\n",
    "1. Amazon Polly\n",
    "1. Amazon Transcribe\n",
    "1. Amazon Translate\n",
    "1. Amazon Comprehend\n",
    "1. Amazon Rekognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Prerequisites\n",
    "\n",
    "1. Create an [Amazon SageMaker Notebook instance](https://docs.aws.amazon.com/sagemaker/latest/dg/howitworks-create-ws.html) and clone the repository to it. Notebook should have an IAM Role with permission to AWS AI Service (Rekognition, Polly, Transcribe, Translate, Comprehend, Comprehend Medical. etc.)\n",
    "2. Lauch [Media Analysis Solution](https://aws.amazon.com/solutions/media-analysis-solution/) by deploying the CloudFormation stack.\n",
    "3. Launch [Amazon Transcribe Websocket Static](https://github.com/aws-samples/amazon-transcribe-websocket-static) by deploying to Amplify Console.\n",
    "4. Create an IAM user to use with Transcribe using the policy defined in this [policy.json](https://github.com/aws-samples/amazon-transcribe-websocket-static/blob/master/policy.json). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Notebook setup\n",
    "\n",
    "Update the following values:\n",
    "* `region` - Make sure you select a region where all the AWS AI services are available.\n",
    "* `bucket_name` - Make sure you enter an existing bucket in the same region as above.\n",
    "* `bucket_prefix` - Enter a prefix if needed, else leave it blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'eu-west-1' # Update it to your region of choice\n",
    "bucket_name = 'aws-mikasino-sagemaker' # Update it to the S3 bucket name\n",
    "bucket_prefix = '' # Make sure you include trailing slash (/) if you are adding a prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the necessary libraries and upload the video file to S3 for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import IPython\n",
    "import time\n",
    "import json\n",
    "import urllib\n",
    "import urllib.request\n",
    "import random\n",
    "from datetime import datetime\n",
    "from prettytable import PrettyTable\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "polly = boto3.client('polly', region_name=region)\n",
    "s3 = boto3.client('s3', region_name=region)\n",
    "\n",
    "s3.upload_file('./jeff.mp4', bucket_name, bucket_prefix + 'jeff.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Demo #1: Amazon Polly\n",
    "\n",
    "[Amazon Polly](https://aws.amazon.com/polly) is a service that turns text into lifelike speech, allowing you to create applications that talk, and build entirely new categories of speech-enabled products. Amazon Polly is a Text-to-Speech (TTS) service that uses advanced deep learning technologies to synthesize speech that sounds like a human voice.\n",
    "\n",
    "---\n",
    "\n",
    "We're making an API call to Amazon Polly service here to convert the text to speech. Text to be converted is in variable `Text` as an SSML string. It will be converted to `mp3` format and stored in a local file.  \n",
    "The voice is controlled by setting the `VoiceId` to `Salli`.\n",
    "\n",
    "For the full list of voices to be used with Polly check [the documentation page](https://docs.aws.amazon.com/en_pv/polly/latest/dg/voicelist.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted text to voice and stored it locally as polly-salli-intro.mp3\n"
     ]
    }
   ],
   "source": [
    "response = polly.synthesize_speech(\n",
    "  Text=\"<speak><amazon:auto-breaths frequency='low' volume='soft' duration='x-short'>Amazon Polly is a Text-to-Speech service, \\\n",
    "  that uses advanced deep learning technologies to synthesize speech that sounds like a human. With dozens of lifelike voices, variety of languages, \\\n",
    "  you can select the ideal voice and build speech-enabled applications that work in many different countries.</amazon:auto-breaths></speak>\",\n",
    "  TextType=\"ssml\",\n",
    "  OutputFormat=\"mp3\",                                           \n",
    "  VoiceId=\"Salli\")\n",
    "    \n",
    "outfile = \"polly-salli-intro.mp3\"\n",
    "data = response['AudioStream'].read()\n",
    "\n",
    "with open(outfile,'wb') as f:\n",
    "  f.write(data)\n",
    "\n",
    "print('Converted text to voice and stored it locally as %s' % (outfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<audio width=\"360\" height=\"270\" controls src=\"polly-salli-intro.mp3\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon Polly supports standard SSML tags such as prosody, which enables you to control the volume, rate, and pitch of the speech out.  \n",
    "In the following example, we demonstrate how you can use manual `<amazon:breath>` and `<prosody>` tags together to convey emotional or dramatic tone in speech.  \n",
    "Let's try with a scared voice of Matthew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted text to voice and stored it locally as polly-matthew-scared.mp3\n"
     ]
    }
   ],
   "source": [
    "response = polly.synthesize_speech(\n",
    "  Text=\"<speak><amazon:breath duration='medium' volume='x-loud'/><prosody rate='115%'> <prosody volume='x-loud'> Salli? <break time='300ms'/> \\\n",
    "  </prosody> Is that you?</prosody></speak>\",\n",
    "  TextType=\"ssml\",\n",
    "  OutputFormat=\"mp3\",                                           \n",
    "  VoiceId=\"Matthew\")\n",
    "    \n",
    "outfile = \"polly-matthew-scared.mp3\"\n",
    "data = response['AudioStream'].read()\n",
    "\n",
    "with open(outfile,'wb') as f:\n",
    "  f.write(data)\n",
    "\n",
    "print('Converted text to voice and stored it locally as %s' % (outfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<audio width=\"360\" height=\"270\" controls src=\"polly-matthew-scared.mp3\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example uses an uncertain voice of Matthew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted text to voice and stored it locally as polly-matthew-uncertain.mp3\n"
     ]
    }
   ],
   "source": [
    "response = polly.synthesize_speech(\n",
    "  Text=\"<speak> <prosody rate='60%'> I am not sure <amazon:breath duration='x-long' volume='soft'/> <break time='150ms'/> </prosody> <prosody rate='90%'>I think I need to think about it. </prosody> </speak>\",\n",
    "  TextType=\"ssml\",\n",
    "  OutputFormat=\"mp3\",                                           \n",
    "  VoiceId=\"Matthew\")\n",
    "    \n",
    "outfile = \"polly-matthew-uncertain.mp3\"\n",
    "data = response['AudioStream'].read()\n",
    "\n",
    "with open(outfile,'wb') as f:\n",
    "  f.write(data)\n",
    "\n",
    "print('Converted text to voice and stored it locally as %s' % (outfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<audio width=\"360\" height=\"270\" controls src=\"polly-matthew-uncertain.mp3\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last example is a breathless voice of Salli.  \n",
    "By incorporating breath sounds into speech output from text, Polly is able to provide more naturally sounding speech, particularly for long-form text narration.  \n",
    "Visit the [Amazon Polly documentation](http://docs.aws.amazon.com/polly/latest/dg/supported-ssml.html) for more information on SSML tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted text to voice and stored it locally as polly-salli-breathless.mp3\n"
     ]
    }
   ],
   "source": [
    "response = polly.synthesize_speech(\n",
    "  Text=\"<speak> <amazon:breath duration='long' volume='x-loud'/><prosody rate='120%'> <prosody volume='loud'> Wow! <amazon:breath duration='long' volume='loud'/> \\\n",
    "  </prosody> That was quite fast <amazon:breath duration='medium' volume='x-loud'/> I almost beat my personal best time on this track. </prosody> </speak>\",\n",
    "  TextType=\"ssml\",\n",
    "  OutputFormat=\"mp3\",                                           \n",
    "  VoiceId=\"Salli\")\n",
    "    \n",
    "outfile = \"polly-salli-breathless.mp3\"\n",
    "data = response['AudioStream'].read()\n",
    "\n",
    "with open(outfile,'wb') as f:\n",
    "  f.write(data)\n",
    "\n",
    "print('Converted text to voice and stored it locally as %s' % (outfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<audio width=\"360\" height=\"270\" controls src=\"polly-salli-breathless.mp3\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Custom Lexicon for Polly\n",
    "\n",
    "Pronunciation lexicons enable you to customize the pronunciation of words. They give you additional control over how Polly pronounces words uncommon to the selected language.  \n",
    "\n",
    "Examples of lexicon usage can be:\n",
    "* If your text includes an acronym, such as W3C. Use a lexicon to define an alias for this so that it is read in the full, expanded form - World Wide Web Consortium.\n",
    "* Common words are sometimes stylized with numbers taking the place of letters, as with \"g3t sm4rt\" (get smart). Humans can read these words correctly. However, a Text-to-Speech (TTS) engine reads the text literally, pronouncing the name exactly as it is spelled. Use a lexicon to customize the synthesized speech for proper pronunciation - get smart.\n",
    "\n",
    "For additional details about Polly Lexicons, refer to the [Managing Lexicons page](https://docs.aws.amazon.com/polly/latest/dg/managing-lexicons.html).\n",
    "\n",
    "Let's use a custom lexicon here to properly convert internet slangs to speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlex = '''<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<lexicon version=\"1.0\" \n",
    "      xmlns=\"http://www.w3.org/2005/01/pronunciation-lexicon\"\n",
    "      xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n",
    "      xsi:schemaLocation=\"http://www.w3.org/2005/01/pronunciation-lexicon \n",
    "        http://www.w3.org/TR/2007/CR-pronunciation-lexicon-20071212/pls.xsd\"\n",
    "      alphabet=\"ipa\" \n",
    "      xml:lang=\"en-US\">\n",
    "  <lexeme>\n",
    "    <grapheme>W3C</grapheme>\n",
    "    <alias>World Wide Web Consortium</alias>\n",
    "  </lexeme>\n",
    "</lexicon>'''\n",
    "\n",
    "internetslanglexicon = '''<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<lexicon version=\"1.0\" \n",
    "      xmlns=\"http://www.w3.org/2005/01/pronunciation-lexicon\"\n",
    "      xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" \n",
    "      xsi:schemaLocation=\"http://www.w3.org/2005/01/pronunciation-lexicon \n",
    "        http://www.w3.org/TR/2007/CR-pronunciation-lexicon-20071212/pls.xsd\"\n",
    "      alphabet=\"ipa\" xml:lang=\"en-US\">\n",
    "  <lexeme>\n",
    "    <grapheme>La vita &#x00E8; bella</grapheme>\n",
    "    <phoneme>ˈlɑ ˈviːɾə ˈʔeɪ ˈbɛlə</phoneme>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>Roberto</grapheme>\n",
    "    <phoneme>ɹəˈbɛːɹɾoʊ</phoneme>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>Benigni</grapheme>\n",
    "    <phoneme>bɛˈniːnji</phoneme>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>IHAC</grapheme>\n",
    "    <alias>I have a customer</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>2day</grapheme>\n",
    "    <alias>Today</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>2moro</grapheme>\n",
    "    <alias>Tomorrow</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>2nite</grapheme>\n",
    "    <alias>Tonite</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>ASAP</grapheme>\n",
    "    <alias>As soon as possible</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>IIRC</grapheme>\n",
    "    <alias>If I remember correctly</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>POV</grapheme>\n",
    "    <alias>Point of View</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>TTYL</grapheme>\n",
    "    <alias>Talk to you later</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>THX</grapheme>\n",
    "    <alias>Thanks</alias>\n",
    "  </lexeme>\n",
    "  <lexeme>\n",
    "    <grapheme>YW</grapheme>\n",
    "    <alias>You are Welcome</alias>\n",
    "  </lexeme>\n",
    "</lexicon>'''\n",
    "# lexicon_data = lexicon_file.read()\n",
    "# response = polly.put_lexicon(Name=arguments.name, Content=lexicon_data)\n",
    "        \n",
    "lexicon = polly.put_lexicon(\n",
    "    Name = 'customlexicon',\n",
    "    Content = internetslanglexicon\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Use Polly to synthesize speech without using custom lexicon and with custom lexicon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted text to voice and stored it locally as polly-joanna-neural_nolexicon.mp3\n",
      "Converted text to voice and stored it locally as polly-joanna-neural_lexicon.mp3\n"
     ]
    }
   ],
   "source": [
    "text_to_convert='''IHAC looking for way to convert text based chat conversations to speech.\n",
    "IIRC, that is possible through custom lexicon in Polly. I want to know your POV on this.\n",
    "I have to respond back to the customer 2nite, hence can you please let me know ASAP, THX.'''\n",
    "\n",
    "no_lex_res = polly.synthesize_speech(\n",
    "  Engine='neural',\n",
    "  Text='<speak>' + text_to_convert +'</speak>',\n",
    "  TextType=\"ssml\",\n",
    "  OutputFormat=\"mp3\",                                           \n",
    "  VoiceId=\"Joanna\")\n",
    "     \n",
    "outfile_nolex = \"polly-joanna-neural_nolexicon.mp3\"\n",
    "data_nolex = no_lex_res['AudioStream'].read()\n",
    "\n",
    "with open(outfile_nolex,'wb') as f:\n",
    "  f.write(data_nolex)\n",
    "\n",
    "print('Converted text to voice and stored it locally as %s' % (outfile_nolex))\n",
    "\n",
    "lex_res = polly.synthesize_speech(\n",
    "  Engine='neural',\n",
    "  Text='<speak>' + text_to_convert +'</speak>',\n",
    "  LexiconNames=['customlexicon'],\n",
    "  TextType=\"ssml\",\n",
    "  OutputFormat=\"mp3\",                                           \n",
    "  VoiceId=\"Joanna\")\n",
    "     \n",
    "outfile_lex = \"polly-joanna-neural_lexicon.mp3\"\n",
    "data_lex = lex_res['AudioStream'].read()\n",
    "\n",
    "with open(outfile_lex,'wb') as f:\n",
    "  f.write(data_lex)\n",
    "\n",
    "print('Converted text to voice and stored it locally as %s' % (outfile_lex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Listen to the synthesized speech without lexicon and with lexicon to hear the difference.\n",
    "\n",
    "Text:  \n",
    "IHAC looking for way to convert text based chat conversations to speech.  \n",
    "IIRC, that is possible through custom lexicon in Polly. I want to know your POV on this.  \n",
    "I have to respond back to the customer 2nite, hence can you please let me know ASAP, THX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Lexicon\n",
    "\n",
    "<audio width=\"360\" height=\"270\" controls src=\"polly-joanna-neural_nolexicon.mp3\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Lexicon\n",
    "\n",
    "<audio width=\"360\" height=\"270\" controls src=\"polly-joanna-neural_lexicon.mp3\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Demo #2: Amazon Transcribe\n",
    "\n",
    "[Amazon Transcribe](https://aws.amazon.com/transcribe/) makes it easy for developers to add speech-to-text capability to their applications. Audio data is virtually impossible for computers to search and analyze. Therefore, recorded speech needs to be converted to text before it can be used in applications. Historically, customers had to work with transcription providers that required them to sign expensive contracts and were hard to integrate into their technology stacks to accomplish this task. Many of these providers use outdated technology that does not adapt well to different scenarios, like low-fidelity phone audio common in contact centers, which results in poor accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "Using Amazon Transcribe we are going to generate the text from the video file. Transcribe will provide a signed S3 URL which will contain the transcribed text in JSON forma. Output of the transcribe will contain the speaker identification labels, timestamp when a particular word was heard, etc.\n",
    "\n",
    "Click the below arrow to expand the video.\n",
    "\n",
    "*Before playing the video, start the transcribe job by executing the next cell since it will take few seconds to complete the transcribe job.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Video to be transcribed</summary>\n",
    "  <video width=\"640\" height=\"480\" controls src=\"./jeff.mp4\" />\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing the video is in progress ......................\n",
      "Transcribing the video job completed with status COMPLETED\n",
      "\n",
      "Download the text output of transcribe job from the following URL:\n",
      "https://s3.eu-west-1.amazonaws.com/aws-transcribe-eu-west-1-prod/892616959688/TranscribeDemo-2019-11-12-154623/6cb7bc5e-678a-47c7-a6b6-f4b12c9f4852/asrOutput.json?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEPD%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCWV1LXdlc3QtMSJHMEUCICKavqq2lAsTupirmWqbIGlhT0Mr4hpJeQrxkT7eZWroAiEAjPctjtMWbkyUuQa0EV8iZjHd4Zob4LZM%2FJWebn9y5I4q0QIIGBABGgw1ODcwMTc2NjM0MTciDHX1pe%2FWHbQH0YqfhCquAnlw0y3mqY63heY509R1og3MKnQ2%2BG%2FgKZuueVnnR119%2FRRZyV%2B33JuP41k5VdNvlq04UvDsxmJrouQu1E90Z9WAn0yY%2BvnoQHUFQdo3TVptjAxZbTqSKHnH54UAQdawfCASi%2BJsdKVyDryw1bWQWGH%2FD%2BWL2an4xXkEqUc5%2FRXXexwbaxT39QHaVNWJGkRpWY2X3lVoVeq7arL%2FNOh4S5Wens%2F0mEvtVbXhwOSFQjNKN%2FG0fZfMqZ6SOn2qm%2FfWp2Himcd6VZLoYXXGqlDulbE6bp7XHjVW%2FHSPqT77BtosoL4KLEWskTCmq4qn4QG4BXdXDXWJfiPAeRAArM6jKkzqZDCxDptaNy45vIfs5YwoaUm6nC5E0iC4Oxh1xBJQRHz2DJmJQu1vfakt7rZIMJ%2Baq%2B4FOs4CKM8dUnSvSxQjWDTmtQcm8WWyhWNa9GY0uTIBAgwZ1WUD17aXslUMScM9uGbLASkX4hb2XbQs3rXiznrFRZLbYH%2FNhX4ImVZmsmTzMLYbQQ864jRxwZMBlyTcF1L2ah2TozDkY9wcbFrfJR52weTEoKyGCvTJRxQfKqB9fmOKZ5HPWqF%2FzKQtGK11Rtz4VefitnNua%2Fom%2B%2BWR0CUUFRCN5Fgt8aPTqt5n97TCDJxb5z9EWIIvfrE1UNzPinbqSVE1F0O5pJDZ5KBjnBVsMSbw91fRRY0%2Fn3v9xBnUUEhQKCg6I4HRdrZkdAVjpPiqT9xjgMr9WGid4SXQ0V0xj2Qzhrj3B%2BUny%2B%2FQyP4JI0d0eQZN5Ro7UIqc3JWAh39kHOtT5DaApJZIvNdYn9KrHArULfy2DXhMmO36TSQGWBNhfpweEXB5vesliuxGT27EDw%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20191112T154815Z&X-Amz-SignedHeaders=host&X-Amz-Expires=900&X-Amz-Credential=ASIAYRLH2WO4TRQ2WYWM%2F20191112%2Feu-west-1%2Fs3%2Faws4_request&X-Amz-Signature=7bdfafff195f64c316c9f5c6a09bb8ee5f9432f410c6b10149fba4902759a0b4 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('transcript_TranscribeDemo-2019-11-12-154623.json',\n",
       " <http.client.HTTPMessage at 0x7fea6e30ea20>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting mp4 to text\n",
    "transcribe = boto3.client('transcribe')\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d-%H%M%S')\n",
    "job_name = \"TranscribeDemo-\" + timestamp\n",
    "job_uri = 'https://s3-{}.amazonaws.com/{}/{}jeff.mp4'.format(region, bucket_name, bucket_prefix)\n",
    "transcribe.start_transcription_job(\n",
    "    TranscriptionJobName=job_name,\n",
    "    Media={'MediaFileUri': job_uri},\n",
    "    MediaFormat='mp4',\n",
    "    LanguageCode='en-US',\n",
    "    MediaSampleRateHertz=44100,\n",
    "    Settings={'MaxSpeakerLabels': 2,'ShowSpeakerLabels': True }    \n",
    ")\n",
    "print('Transcribing the video is in progress ', end='')\n",
    "while True:\n",
    "    status = transcribe.get_transcription_job(TranscriptionJobName=job_name)\n",
    "    if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
    "        print('')\n",
    "        print('Transcribing the video job completed with status %s\\n' % status['TranscriptionJob']['TranscriptionJobStatus'])\n",
    "        break\n",
    "    print('.', end='')\n",
    "    time.sleep(5)\n",
    "# pprint(status)\n",
    "url = status['TranscriptionJob']['Transcript']['TranscriptFileUri']\n",
    "print('Download the text output of transcribe job from the following URL:\\n%s ' % url)\n",
    "transcript='transcript_{}.json'.format(job_name)\n",
    "urllib.request.urlretrieve(url,transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Read the output of the transcribe job and print the text generated from the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I guess my first question is, Is this Is this the underpinnings of tech over the next 10 years as we seem to be emerging from the period of frantic growth and development in smartphones? Well, I think it's I think it's gigantic. Um, I do, I think, natural language understanding, I think machine learning in general, Artificial intelligence. Uh, this. It's hard to overstate how big of an impact it's gonna have on society over the next 20 years, so\n"
     ]
    }
   ],
   "source": [
    "result = json.load(open(transcript))\n",
    "transcript_text = result['results']['transcripts'][0]['transcript']\n",
    "print(transcript_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now we are going to label the text based on the speaker labels to display the content specifically spoken by a speaker.\n",
    "\n",
    "We also use Amazon Comprehend to identify the sentiment of the text for both he speakers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker1:\n",
      "I guess my first question is,Is thisIs this the underpinnings of tech over the next 10 years as we seem to be emerging from the period of frantic growth and development in smartphones?\n",
      "Well,I think it's\n",
      "Sentiment of speaker 1 :  Mixed : 2.5586166884750128e-05\t Positive :0.021759752184152603\t Negative : 0.13760659098625183\t Neutral : 0.8406080603599548\t Sentiment : NEUTRAL\n",
      "\n",
      "\n",
      "Speaker2:\n",
      "I think it's gigantic.\n",
      "Um,I do,I think, natural language understanding,I think machine learning in general,Artificial intelligence.\n",
      "Uh, this.\n",
      "It's hard to overstate how big of an impact it's gonna have on society over the next 20 years, so\n",
      "\n",
      "\n",
      "Sentiment of speaker 2 :  Mixed : 1.1363149496901315e-05\t Positive :0.4650130271911621\t Negative : 0.0057877665385603905\t Neutral : 0.529187798500061\t Sentiment : NEUTRAL\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# read the json output from disk (debugging)\n",
    "with open('asrOutput.json') as f:\n",
    "    data = json.load(f)\n",
    "'''\n",
    "\n",
    "data = json.load(open(transcript))\n",
    "\n",
    "# create a list to store start and stop times of the speaker in seconds\n",
    "spk_0 = []\n",
    "spk_1 = []\n",
    "\n",
    "# iterate over the speaker segments from the json\n",
    "for x in data['results']['speaker_labels']['segments']:\n",
    "        # check for which speaker a label was submitted\n",
    "        if x['speaker_label'] == 'spk_0':\n",
    "                # we need to convert float to int by multiplying *100, else we cannot use it later on to compare ranges\n",
    "                start         = int(float(x['start_time']) * 100)\n",
    "                end         = int(float(x['end_time']) * 100)\n",
    "\n",
    "                # append the start and stop times to a list\n",
    "                spk_0.append([start, end])\n",
    "\n",
    "        # check for which speaker a label was submitted\n",
    "        if x['speaker_label'] == 'spk_1':\n",
    "                # we need to convert float to int by multiplying *100, else we cannot use it later on to compare ranges\n",
    "                start         = int(float(x['start_time']) * 100)\n",
    "                end         = int(float(x['end_time']) * 100)\n",
    "\n",
    "                # append the start and stop times to a list\n",
    "                spk_1.append([start, end])\n",
    "\n",
    "res = []\n",
    "speaker0                 = []\n",
    "speaker1                 = []\n",
    "curr_speaker         = ''\n",
    "\n",
    "\n",
    "for x in data['results']['items']:\n",
    "        txt         = x['alternatives'][0]['content']\n",
    "        # check if the item has a start_time - if not, its probably punctuation which doesn't come with a timestamp. \n",
    "        if 'start_time' in x:\n",
    "                start         = int(float(x['start_time']) * 100)\n",
    "                end         = int(float(x['end_time']) * 100)\n",
    "                for y in spk_0:                        \n",
    "                        if start in range(y[0], y[1]) and end in range(y[0], y[1]):\n",
    "                                curr_speaker = 'spk_0'\n",
    "                for y in spk_1:                        \n",
    "                        if start in range(y[0], y[1]) and end in range(y[0], y[1]):\n",
    "                                curr_speaker = 'spk_1'\n",
    "        if curr_speaker == 'spk_0':\n",
    "                if x['type'] == 'punctuation' and txt != ',':\n",
    "                        speaker0.append(txt+'\\n')\n",
    "                elif txt == ',' or txt[0].isupper():\n",
    "                        speaker0.append(txt)\n",
    "                else:\n",
    "                        speaker0.append(' '+txt)\n",
    "        if curr_speaker == 'spk_1':\n",
    "                if x['type'] == 'punctuation' and txt != ',':\n",
    "                        speaker1.append(txt+'\\n')\n",
    "                elif txt == ',' or txt[0].isupper():\n",
    "                        speaker1.append(txt)\n",
    "                else:\n",
    "                        speaker1.append(' '+txt)\n",
    "\n",
    "# check sentiment of both speakers\n",
    "def check_sentiment(x, y):\n",
    "        c = boto3.client(service_name='comprehend', region_name='eu-west-1')\n",
    "        s = y+','\n",
    "        x = c.detect_sentiment(Text=x, LanguageCode='en')\n",
    "        y =  ' Mixed : '+str(x['SentimentScore']['Mixed'])\n",
    "        y += '\\t Positive :'+str(x['SentimentScore']['Positive'])\n",
    "        y += '\\t Negative : '+str(x['SentimentScore']['Negative'])\n",
    "        y += '\\t Neutral : '+str(x['SentimentScore']['Neutral'])\n",
    "        y += '\\t Sentiment : '+str(x['Sentiment'])\n",
    "        return y\n",
    "\n",
    "\n",
    "# print full text for both speakers\n",
    "print('Speaker1:')\n",
    "print(''.join(speaker1))\n",
    "print('Sentiment of speaker 1 : '+check_sentiment(''.join(speaker1), 'speaker 1 '))\n",
    "print('\\n')\n",
    "print('Speaker2:')\n",
    "print(''.join(speaker0))\n",
    "print('\\n')\n",
    "print('Sentiment of speaker 2 : '+check_sentiment(''.join(speaker0), 'speaker 0 '))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Demo #3: Amazon Translate\n",
    "\n",
    "[Amazon Translate](https://aws.amazon.com/translate) is a neural machine translation service that delivers fast, high-quality, and affordable language translation. Neural machine translation is a form of language translation automation that uses deep learning models to deliver more accurate and more natural sounding translation than traditional statistical and rule-based translation algorithms. Amazon Translate allows you to localize content - such as websites and applications - for international users, and to easily translate large volumes of text efficiently. Amazon Translate supports translation between 32 languages. [More details here](https://aws.amazon.com/translate/details/).\n",
    "\n",
    "---\n",
    "\n",
    "We will now convert the transribed text to German, Polish, and French languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ich denke, meine erste Frage ist, ist das die Grundlagen der Technologie in den nächsten 10 Jahren, da wir aus der Zeit des hektischen Wachstums und der Entwicklung in Smartphones entstehen scheinen? Nun, ich glaube, ich denke, es ist gigantisch. Ähm, ich denke, natürliches Sprachverständnis, ich denke, maschinelles Lernen im Allgemeinen, künstliche Intelligenz. Äh, das hier. Es ist schwer zu übertreiben, wie groß es für die Gesellschaft in den nächsten 20 Jahren sein wird, also \n",
      "\n",
      "Myślę, że moje pierwsze pytanie brzmi: Czy to jest podstawą technologii w ciągu najbliższych 10 lat, kiedy wydaje się, że wyłaniamy się z okresu szaleńczego wzrostu i rozwoju smartfonów? Myślę, że to jest gigantyczne. Um, myślę, że zrozumienie języka naturalnego, myślę, że uczenie maszynowe w ogóle, sztuczna inteligencja. Uh, tego. Trudno zawyżać, jak duży będzie to miało wpływ na społeczeństwo w ciągu najbliższych 20 lat, więc \n",
      "\n",
      "Je suppose que ma première question est : Est-ce là les fondements de la technologie au cours des 10 prochaines années alors que nous semblons sortir de la période de croissance et de développement effrénés des smartphones ? Eh bien, je pense que c'est que je trouve ça gigantesque. Je pense que la compréhension du langage naturel, l'apprentissage automatique en général, l'intelligence artificielle. Euh, ça. Il est difficile de surestimer l'impact que cela aura sur la société au cours des 20 prochaines années, donc\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "translate = boto3.client('translate', region_name=region)\n",
    "\n",
    "message = transcript_text\n",
    "\n",
    "result=translate.translate_text(\n",
    "    Text=message,\n",
    "    SourceLanguageCode='en',\n",
    "    TargetLanguageCode='de'\n",
    ")\n",
    "print(result['TranslatedText'], '\\n')\n",
    "\n",
    "result=translate.translate_text(\n",
    "    Text=message,\n",
    "    SourceLanguageCode='en',\n",
    "    TargetLanguageCode='pl'\n",
    ")\n",
    "print(result['TranslatedText'], '\\n')\n",
    "\n",
    "result=translate.translate_text(\n",
    "    Text=message,\n",
    "    SourceLanguageCode='en',\n",
    "    TargetLanguageCode='fr'\n",
    ")\n",
    "print(result['TranslatedText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Demo #4: Amazon Comprehend\n",
    "\n",
    "[Amazon Comprehend](https://aws.amazon.com/comprehend/) is a machine learning powered service that makes it easy to find insights and relationships in text.\n",
    "\n",
    "Customer emails, support tickets, product reviews, call center conversations, and social media contain a rich amount of information about your business. However, because this type of data is unstructured and messy, it’s hard to extract relevant and meaningful insights at scale. As a result, most of it goes unused. Amazon Comprehend solves this problem using natural language processing (NLP) to automatically identify the language of the text, extract key phrases, places, people, brands, or events; understand positive or negative sentiment; and automatically organize a collection of text files by topic. To build a custom set of entities or text classification models that are tailored uniquely to your organization’s needs you can use AutoML, or to extract complex medical information from unstructured text, you can use Amazon Comprehend Medical.\n",
    "\n",
    "---\n",
    "\n",
    "Now using Amazon Comprehend detect the language from the above text. By providing the detected language as input detect the sentiment, entities and key phrases in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehend = boto3.client('comprehend')\n",
    "\n",
    "text = result['TranslatedText']\n",
    "\n",
    "# text = \"I guess my first question is, Is this Is this the underpinnings of tech over the next 10 years as we seem to be emerging from the period of frantic growth and development in smartphones? Well, I think it's I think it's gigantic. Um, I do, I think, natural language understanding, I think machine learning in general, Artificial intelligence. Uh, this. It's hard to overstate how big of an impact it's gonna have on society over the next 20 years, so\"\n",
    "\n",
    "language_detected = comprehend.detect_dominant_language(Text=text)['Languages'][0]['LanguageCode']\n",
    "\n",
    "entity_res = comprehend.detect_entities(Text=text, LanguageCode=language_detected)\n",
    "senti_res = comprehend.detect_sentiment(Text=text, LanguageCode=language_detected)\n",
    "key_res = comprehend.detect_key_phrases(Text=text, LanguageCode=language_detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language detected is fr \n",
      "\n",
      "Sentiment of the text has been identified as NEUTRAL with the score of 0.9789438247680664 \n",
      "\n",
      "Key Phrases identified from the text:\n",
      "+-------+----------------------------------------------+\n",
      "| Score |                 Key Phrases                  |\n",
      "+-------+----------------------------------------------+\n",
      "|  .99  |                      Je                      |\n",
      "|       |                     nous                     |\n",
      "|       |                      je                      |\n",
      "|       |                                              |\n",
      "|   --  |             --------------------             |\n",
      "|  .98  |                  croissance                  |\n",
      "|       |                      Je                      |\n",
      "|       |                     cela                     |\n",
      "|       | la société au cours des 20 prochaines années |\n",
      "|       |                                              |\n",
      "|   --  |             --------------------             |\n",
      "|  .97  |     la compréhension du langage naturel      |\n",
      "|       |                                              |\n",
      "+-------+----------------------------------------------+\n",
      "\n",
      "\n",
      "Top 10 entities identified:\n",
      "+----------------------+----------+--------------------+\n",
      "|         Text         |   Type   |       Score        |\n",
      "+----------------------+----------+--------------------+\n",
      "|  première question   | QUANTITY | 0.9945557713508606 |\n",
      "| 20 prochaines années |   DATE   | 0.8536403179168701 |\n",
      "| 10 prochaines années |   DATE   | 0.8523039817810059 |\n",
      "+----------------------+----------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "print('Language detected is %s \\n' % language_detected)\n",
    "\n",
    "print('Sentiment of the text has been identified as %s with the score of %s \\n' % (senti_res['Sentiment'], senti_res['SentimentScore'][senti_res['Sentiment'].title()]))\n",
    "\n",
    "keyphrases = [[], [], []]\n",
    "for k in key_res['KeyPhrases']:\n",
    "    if k['Score'] > .99:\n",
    "        keyphrases[0].append(k['Text'] + '\\n')\n",
    "    elif k['Score'] > .98:\n",
    "        keyphrases[1].append(k['Text'] + '\\n')\n",
    "    elif k['Score'] > .97:\n",
    "        keyphrases[2].append(k['Text'] + '\\n')\n",
    "           \n",
    "print('Key Phrases identified from the text:')\n",
    "\n",
    "keytable = PrettyTable(['Score', 'Key Phrases'])\n",
    "if keyphrases[0]:\n",
    "    keytable.add_row(['.99', ''.join(keyphrases[0])])\n",
    "    keytable.add_row(['--', '--------------------'])\n",
    "if keyphrases[1]:\n",
    "    keytable.add_row(['.98', ''.join(keyphrases[1])])\n",
    "    keytable.add_row(['--', '--------------------'])\n",
    "if keyphrases[2]:\n",
    "    keytable.add_row(['.97', ''.join(keyphrases[2])])\n",
    "print(keytable)\n",
    "print('\\n')\n",
    "\n",
    "entity_thershold = 0.80\n",
    "\n",
    "topentity = {}\n",
    "for e in entity_res['Entities']:\n",
    "    if e['Score'] > entity_thershold:\n",
    "        topentity[e['Score']] = {e['Text']: e['Type']}\n",
    "        \n",
    "top10 = sorted(topentity, reverse=True)[:10]\n",
    "\n",
    "table = PrettyTable(['Text', 'Type','Score'])\n",
    "for t in top10:\n",
    "    table.add_row([list(topentity[t].keys())[0], list(topentity[t].values())[0], t])\n",
    "    \n",
    "print('Top 10 entities identified:')    \n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Real-time Audio Transcription using Amazon Transcribe Websockets\n",
    "\n",
    "Earlier we have seen how to transcribe an existing video file stored in S3. Now let's look at an example how we can to real-time audio transcripton using the Amazon Transcribe Websockets API.\n",
    "\n",
    "Did you deploy the [Amazon Transcribe Websocket Static](https://github.com/aws-samples/amazon-transcribe-websocket-static) to Amplify Console yet?\n",
    "\n",
    "Update two URLs below with the actual Amplify Console URL created as part of the prerequisites. You also need to key in the access key and secret key of the user that you created as part of the prerequisites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Real-time Audio Transcription</h3>\n",
       "<br>\n",
       "<object type=\"text/html\" data=https://master.d1fkgg5fc0fb3p.amplifyapp.com/ width=\"1000\" height=\"600\"> <embed src=\"https://master.d1fkgg5fc0fb3p.amplifyapp.com/\"></embed></object>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<h3>Real-time Audio Transcription</h3>\n",
    "<br>\n",
    "<object type=\"text/html\" data=https://master.d1fkgg5fc0fb3p.amplifyapp.com/ width=\"1000\" height=\"600\"> <embed src=\"https://master.d1fkgg5fc0fb3p.amplifyapp.com/\"></embed></object>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Demo #5: Amazon Rekognition\n",
    "\n",
    "[Amazon Rekognition](https://aws.amazon.com/rekognition/) makes it easy to add image and video analysis to your applications. You just provide an image or video to the Rekognition API, and the service can identify the objects, people, text, scenes, and activities, as well as detect any inappropriate content. Amazon Rekognition also provides highly accurate facial analysis and facial recognition on images and video that you provide. You can detect, analyze, and compare faces for a wide variety of user verification, people counting, and public safety use cases.\n",
    "\n",
    "---\n",
    "\n",
    "Remember [Media Analysis Solution](https://aws.amazon.com/solutions/media-analysis-solution/) CloudFormation stack?  \n",
    "Get the DemoWebsite URL from the Outputs section of the Media Analysis Solution CloudFormation stack. Replace the two URLs below with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Media Analysis Solution</h3>\n",
       "<br>\n",
       "<object type=\"text/html\" data=https://d33pfno8pkdlkm.cloudfront.net/ width=\"1000\" height=\"600\"> <embed src=\"https://d33pfno8pkdlkm.cloudfront.net/\"></embed></object>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<h3>Media Analysis Solution</h3>\n",
    "<br>\n",
    "<object type=\"text/html\" data=https://d33pfno8pkdlkm.cloudfront.net/ width=\"1000\" height=\"600\"> <embed src=\"https://d33pfno8pkdlkm.cloudfront.net/\"></embed></object>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
